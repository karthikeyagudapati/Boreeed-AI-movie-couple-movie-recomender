
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Netflix Joint Recommendation System - Comprehensive Data Analysis\n",
    "\n",
    "## üìä Complete Exploratory Data Analysis & Model Development\n",
    "\n",
    "**Author:** Your Name  \n",
    "**Date:** January 2024  \n",
    "**Purpose:** Comprehensive analysis of MovieLens data for building a joint recommendation system\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Analysis Objectives\n",
    "\n",
    "1. **Data Understanding**: Deep dive into MovieLens dataset structure and quality\n",
    "2. **User Behavior Analysis**: Understand individual viewing patterns and preferences\n",
    "3. **Group Dynamics**: Explore how users with different tastes can find common ground\n",
    "4. **Algorithm Development**: Build and evaluate joint recommendation algorithms\n",
    "5. **Visualization**: Create compelling visualizations for stakeholder presentation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"üé¨ Netflix Joint Recommendation System - Data Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• 1. Data Loading & Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Load MovieLens Dataset\n",
    "# Note: In practice, you would download from https://grouplens.org/datasets/movielens/\n",
    "\n",
    "# For demonstration, we'll create comprehensive sample data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate realistic sample data\n",
    "def generate_sample_movielens_data():\n",
    "    \"\"\"Generate realistic MovieLens-style sample data for demonstration\"\"\"\n",
    "    \n",
    "    # Movies data\n",
    "    movie_titles = [\n",
    "        \"The Shawshank Redemption\", \"The Godfather\", \"The Dark Knight\", \"Pulp Fiction\",\n",
    "        \"The Lord of the Rings: The Return of the King\", \"Forrest Gump\", \"Star Wars\",\n",
    "        \"The Matrix\", \"Goodfellas\", \"One Flew Over the Cuckoo's Nest\", \"Inception\",\n",
    "        \"The Silence of the Lambs\", \"Saving Private Ryan\", \"Schindler's List\",\n",
    "        \"Terminator 2\", \"Back to the Future\", \"The Lion King\", \"Gladiator\",\n",
    "        \"Titanic\", \"The Departed\", \"Interstellar\", \"The Prestige\", \"Memento\",\n",
    "        \"Fight Club\", \"The Usual Suspects\", \"Se7en\", \"Casablanca\", \"Citizen Kane\",\n",
    "        \"Vertigo\", \"Psycho\", \"North by Northwest\", \"Rear Window\", \"Singin' in the Rain\",\n",
    "        \"Gone with the Wind\", \"Lawrence of Arabia\", \"2001: A Space Odyssey\",\n",
    "        \"Sunset Boulevard\", \"Apocalypse Now\", \"Taxi Driver\", \"Chinatown\",\n",
    "        \"The Wizard of Oz\", \"City Lights\", \"The Searchers\", \"Raging Bull\",\n",
    "        \"Some Like It Hot\", \"Dr. Strangelove\", \"On the Waterfront\", \"The Treasure of the Sierra Madre\",\n",
    "        \"The Philadelphia Story\", \"Mr. Smith Goes to Washington\"\n",
    "    ]\n",
    "    \n",
    "    genres_list = [\n",
    "        \"Drama\", \"Crime|Drama\", \"Action|Crime|Drama\", \"Crime|Drama\",\n",
    "        \"Adventure|Drama|Fantasy\", \"Drama|Romance\", \"Adventure|Fantasy|Sci-Fi\",\n",
    "        \"Action|Sci-Fi\", \"Biography|Crime|Drama\", \"Drama\", \"Action|Mystery|Sci-Fi\",\n",
    "        \"Crime|Drama|Thriller\", \"Drama|War\", \"Biography|Drama|History\",\n",
    "        \"Action|Sci-Fi\", \"Adventure|Comedy|Sci-Fi\", \"Animation|Drama|Family\", \"Action|Adventure|Drama\",\n",
    "        \"Drama|Romance\", \"Crime|Drama|Thriller\", \"Adventure|Drama|Sci-Fi\", \"Drama|Mystery|Sci-Fi\", \"Mystery|Thriller\",\n",
    "        \"Drama\", \"Crime|Mystery|Thriller\", \"Crime|Drama|Mystery\", \"Drama|Romance\", \"Drama|Mystery\",\n",
    "        \"Mystery|Romance|Thriller\", \"Horror|Mystery|Thriller\", \"Action|Adventure|Thriller\", \"Mystery|Thriller\", \"Comedy|Musical|Romance\",\n",
    "        \"Drama|Romance|War\", \"Adventure|Biography|Drama\", \"Adventure|Sci-Fi\",\n",
    "        \"Drama|Film-Noir\", \"Drama|War\", \"Crime|Drama\", \"Drama|Mystery|Thriller\",\n",
    "        \"Adventure|Family|Fantasy\", \"Comedy|Drama|Romance\", \"Adventure|Drama|Western\", \"Biography|Drama|Sport\",\n",
    "        \"Comedy|Romance\", \"Comedy|War\", \"Crime|Drama\", \"Adventure|Drama|Western\",\n",
    "        \"Comedy|Romance\", \"Comedy|Drama\"\n",
    "    ]\n",
    "    \n",
    "    years = np.random.choice(range(1940, 2020), len(movie_titles))\n",
    "    \n",
    "    movies_df = pd.DataFrame({\n",
    "        'movie_id': range(1, len(movie_titles) + 1),\n",
    "        'title': movie_titles,\n",
    "        'genres': genres_list[:len(movie_titles)],\n",
    "        'year': years\n",
    "    })\n",
    "    \n",
    "    # Generate ratings data\n",
    "    n_users = 1000\n",
    "    n_ratings = 50000\n",
    "    \n",
    "    # Create user preferences (some users prefer certain genres)\n",
    "    user_preferences = {}\n",
    "    genre_types = ['Drama', 'Action', 'Comedy', 'Sci-Fi', 'Romance', 'Thriller']\n",
    "    \n",
    "    for user_id in range(1, n_users + 1):\n",
    "        # Each user has 1-3 preferred genres\n",
    "        n_prefs = np.random.choice([1, 2, 3], p=[0.3, 0.5, 0.2])\n",
    "        preferred_genres = np.random.choice(genre_types, n_prefs, replace=False)\n",
    "        user_preferences[user_id] = preferred_genres\n",
    "    \n",
    "    # Generate ratings based on preferences\n",
    "    ratings_data = []\n",
    "    \n",
    "    for _ in range(n_ratings):\n",
    "        user_id = np.random.randint(1, n_users + 1)\n",
    "        movie_id = np.random.randint(1, len(movie_titles) + 1)\n",
    "        \n",
    "        # Get movie genres\n",
    "        movie_genres = movies_df[movies_df['movie_id'] == movie_id]['genres'].iloc[0]\n",
    "        \n",
    "        # Check if user likes this genre\n",
    "        user_prefs = user_preferences[user_id]\n",
    "        likes_genre = any(pref in movie_genres for pref in user_prefs)\n",
    "        \n",
    "        # Generate rating based on preference\n",
    "        if likes_genre:\n",
    "            # Higher ratings for preferred genres\n",
    "            rating = np.random.choice([3, 4, 5], p=[0.2, 0.4, 0.4])\n",
    "        else:\n",
    "            # Lower ratings for non-preferred genres\n",
    "            rating = np.random.choice([1, 2, 3, 4], p=[0.2, 0.3, 0.3, 0.2])\n",
    "        \n",
    "        # Add some noise\n",
    "        if np.random.random() < 0.1:\n",
    "            rating = np.random.randint(1, 6)\n",
    "        \n",
    "        timestamp = np.random.randint(946684800, 1577836800)  # 2000-2020\n",
    "        \n",
    "        ratings_data.append({\n",
    "            'user_id': user_id,\n",
    "            'movie_id': movie_id,\n",
    "            'rating': float(rating),\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "    \n",
    "    ratings_df = pd.DataFrame(ratings_data).drop_duplicates(subset=['user_id', 'movie_id'])\n",
    "    \n",
    "    return ratings_df, movies_df, user_preferences\n",
    "\n",
    "# Generate sample data\n",
    "print(\"üîÑ Generating comprehensive sample dataset...\")\n",
    "ratings_df, movies_df, user_preferences = generate_sample_movielens_data()\n",
    "\n",
    "print(f\"‚úÖ Dataset generated successfully!\")\n",
    "print(f\"üìä Ratings: {len(ratings_df):,} records\")\n",
    "print(f\"üé¨ Movies: {len(movies_df):,} titles\")\n",
    "print(f\"üë• Users: {ratings_df['user_id'].nunique():,} unique users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Initial Data Exploration\n",
    "print(\"üìã DATASET OVERVIEW\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Ratings dataset info\n",
    "print(\"\\nüéØ RATINGS DATASET:\")\n",
    "print(f\"Shape: {ratings_df.shape}\")\n",
    "print(f\"Memory usage: {ratings_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nColumn types:\")\n",
    "print(ratings_df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "# Movies dataset info\n",
    "print(\"\\n\\nüé¨ MOVIES DATASET:\")\n",
    "print(f\"Shape: {movies_df.shape}\")\n",
    "print(\"\\nColumn types:\")\n",
    "print(movies_df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(movies_df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n\\nüìä BASIC STATISTICS:\")\n",
    "print(f\"Rating range: {ratings_df['rating'].min():.1f} - {ratings_df['rating'].max():.1f}\")\n",
    "print(f\"Average rating: {ratings_df['rating'].mean():.2f}\")\n",
    "print(f\"Rating std: {ratings_df['rating'].std():.2f}\")\n",
    "print(f\"Most active user rated {ratings_df['user_id'].value_counts().max()} movies\")\n",
    "print(f\"Most rated movie has {ratings_df['movie_id'].value_counts().max()} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 2. Comprehensive Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Data Quality Assessment\n",
    "def analyze_data_quality(ratings_df, movies_df):\n",
    "    \"\"\"Comprehensive data quality analysis\"\"\"\n",
    "    \n",
    "    quality_report = {}\n",
    "    \n",
    "    # Missing values\n",
    "    quality_report['missing_values'] = {\n",
    "        'ratings': ratings_df.isnull().sum().to_dict(),\n",
    "        'movies': movies_df.isnull().sum().to_dict()\n",
    "    }\n",
    "    \n",
    "    # Duplicates\n",
    "    quality_report['duplicates'] = {\n",
    "        'ratings_duplicates': ratings_df.duplicated().sum(),\n",
    "        'user_movie_duplicates': ratings_df[['user_id', 'movie_id']].duplicated().sum(),\n",
    "        'movies_duplicates': movies_df.duplicated().sum()\n",
    "    }\n",
    "    \n",
    "    # Data ranges and validity\n",
    "    quality_report['data_validity'] = {\n",
    "        'rating_range': (ratings_df['rating'].min(), ratings_df['rating'].max()),\n",
    "        'valid_ratings': ((ratings_df['rating'] >= 1) & (ratings_df['rating'] <= 5)).all(),\n",
    "        'timestamp_range': (ratings_df['timestamp'].min(), ratings_df['timestamp'].max()),\n",
    "        'movie_year_range': (movies_df['year'].min(), movies_df['year'].max())\n",
    "    }\n",
    "    \n",
    "    # Sparsity analysis\n",
    "    n_users = ratings_df['user_id'].nunique()\n",
    "    n_movies = ratings_df['movie_id'].nunique()\n",
    "    n_ratings = len(ratings_df)\n",
    "    possible_ratings = n_users * n_movies\n",
    "    sparsity = 1 - (n_ratings / possible_ratings)\n",
    "    \n",
    "    quality_report['sparsity'] = {\n",
    "        'total_possible_ratings': possible_ratings,\n",
    "        'actual_ratings': n_ratings,\n",
    "        'sparsity_percentage': sparsity * 100,\n",
    "        'density_percentage': (1 - sparsity) * 100\n",
    "    }\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Perform quality analysis\n",
    "quality_report = analyze_data_quality(ratings_df, movies_df)\n",
    "\n",
    "print(\"üîç DATA QUALITY ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nüìã Missing Values:\")\n",
    "for dataset, missing in quality_report['missing_values'].items():\n",
    "    print(f\"  {dataset}: {missing}\")\n",
    "\n",
    "print(\"\\nüîÑ Duplicates:\")\n",
    "for dup_type, count in quality_report['duplicates'].items():\n",
    "    print(f\"  {dup_type}: {count}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data Validity:\")\n",
    "for check, result in quality_report['data_validity'].items():\n",
    "    print(f\"  {check}: {result}\")\n",
    "\n",
    "print(\"\\nüï≥Ô∏è Sparsity Analysis:\")\n",
    "sparsity_info = quality_report['sparsity']\n",
    "print(f\"  Matrix size: {sparsity_info['total_possible_ratings']:,} possible ratings\")\n",
    "print(f\"  Actual ratings: {sparsity_info['actual_ratings']:,}\")\n",
    "print(f\"  Sparsity: {sparsity_info['sparsity_percentage']:.2f}%\")\n",
    "print(f\"  Density: {sparsity_info['density_percentage']:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 3. Advanced Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Rating Distribution Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('üìä Rating Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Overall rating distribution\n",
    "axes[0, 0].hist(ratings_df['rating'], bins=np.arange(0.5, 6, 1), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Overall Rating Distribution')\n",
    "axes[0, 0].set_xlabel('Rating')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics to the plot\n",
    "mean_rating = ratings_df['rating'].mean()\n",
    "median_rating = ratings_df['rating'].median()\n",
    "axes[0, 0].axvline(mean_rating, color='red', linestyle='--', label=f'Mean: {mean_rating:.2f}')\n",
    "axes[0, 0].axvline(median_rating, color='green', linestyle='--', label=f'Median: {median_rating:.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Rating distribution by user (sample of users)\n",
    "sample_users = ratings_df['user_id'].value_counts().head(20).index\n",
    "user_ratings = [ratings_df[ratings_df['user_id'] == user]['rating'].values for user in sample_users]\n",
    "axes[0, 1].boxplot(user_ratings, labels=[f'U{i}' for i in range(len(sample_users))])\n",
    "axes[0, 1].set_title('Rating Patterns - Top 20 Active Users')\n",
    "axes[0, 1].set_xlabel('User')\n",
    "axes[0, 1].set_ylabel('Rating')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Ratings per user distribution\n",
    "ratings_per_user = ratings_df['user_id'].value_counts()\n",
    "axes[1, 0].hist(ratings_per_user, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Distribution of Ratings per User')\n",
    "axes[1, 0].set_xlabel('Number of Ratings')\n",
    "axes[1, 0].set_ylabel('Number of Users')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ratings per movie distribution\n",
    "ratings_per_movie = ratings_df['movie_id'].value_counts()\n",
    "axes[1, 1].hist(ratings_per_movie, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1, 1].set_title('Distribution of Ratings per Movie')\n",
    "axes[1, 1].set_xlabel('Number of Ratings')\n",
    "axes[1, 1].set_ylabel('Number of Movies')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"üìä DETAILED RATING STATISTICS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total ratings: {len(ratings_df):,}\")\n",
    "print(f\"Average rating: {ratings_df['rating'].mean():.3f}\")\n",
    "print(f\"Standard deviation: {ratings_df['rating'].std():.3f}\")\n",
    "print(f\"Skewness: {stats.skew(ratings_df['rating']):.3f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(ratings_df['rating']):.3f}\")\n",
    "\n",
    "print(\"\\nüìä Rating Distribution:\")\n",
    "rating_counts = ratings_df['rating'].value_counts().sort_index()\n",
    "for rating, count in rating_counts.items():\n",
    "    percentage = (count / len(ratings_df)) * 100\n",
    "    print(f\"  {rating:.0f} stars: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nüë• User Activity Statistics:\")\n",
    "print(f\"Total users: {ratings_df['user_id'].nunique():,}\")\n",
    "print(f\"Average ratings per user: {ratings_per_user.mean():.1f}\")\n",
    "print(f\"Median ratings per user: {ratings_per_user.median():.1f}\")\n",
    "print(f\"Most active user: {ratings_per_user.max()} ratings\")\n",
    "print(f\"Users with only 1 rating: {(ratings_per_user == 1).sum():,}\")\n",
    "\n",
    "print(\"\\nüé¨ Movie Popularity Statistics:\")\n",
    "print(f\"Total movies: {ratings_df['movie_id'].nunique():,}\")\n",
    "print(f\"Average ratings per movie: {ratings_per_movie.mean():.1f}\")\n",
    "print(f\"Median ratings per movie: {ratings_per_movie.median():.1f}\")\n",
    "print(f\"Most rated movie: {ratings_per_movie.max()} ratings\")\n",
    "print(f\"Movies with only 1 rating: {(ratings_per_movie == 1).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ 4. Genre Analysis & Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé≠ Comprehensive Genre Analysis\n",
    "def analyze_genres(ratings_df, movies_df):\n",
    "    \"\"\"Analyze genre preferences and patterns\"\"\"\n",
    "    \n",
    "    # Merge ratings with movie info\n",
    "    ratings_with_movies = ratings_df.merge(movies_df, on='movie_id')\n",
    "    \n",
    "    # Extract all genres\n",
    "    all_genres = []\n",
    "    genre_ratings = []\n",
    "    \n",
    "    for _, row in ratings_with_movies.iterrows():\n",
    "        if pd.notna(row['genres']):\n",
    "            genres = row['genres'].split('|')\n",
    "            for genre in genres:\n",
    "                all_genres.append(genre)\n",
    "                genre_ratings.append({\n",
    "                    'genre': genre,\n",
    "                    'rating': row['rating'],\n",
    "                    'user_id': row['user_id'],\n",
    "                    'movie_id': row['movie_id']\n",
    "                })\n",
    "    \n",
    "    genre_df = pd.DataFrame(genre_ratings)\n",
    "    \n",
    "    # Genre statistics\n",
    "    genre_stats = genre_df.groupby('genre').agg({\n",
    "        'rating': ['count', 'mean', 'std'],\n",
    "        'user_id': 'nunique',\n",
    "        'movie_id': 'nunique'\n",
    "    }).round(3)\n",
    "    \n",
    "    genre_stats.columns = ['total_ratings', 'avg_rating', 'rating_std', 'unique_users', 'unique_movies']\n",
    "    genre_stats = genre_stats.sort_values('total_ratings', ascending=False)\n",
    "    \n",
    "    return genre_df, genre_stats\n",
    "\n",
    "# Perform genre analysis\n",
    "genre_df, genre_stats = analyze_genres(ratings_df, movies_df)\n",
    "\n",
    "print(\"üé≠ GENRE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total unique genres: {len(genre_stats)}\")\n",
    "print(f\"Total genre-rating combinations: {len(genre_df):,}\")\n",
    "\n",
    "print(\"\\nüèÜ Top 10 Most Popular Genres:\")\n",
    "print(genre_stats.head(10))\n",
    "\n",
    "# Create comprehensive genre visualizations\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Genre Popularity (Total Ratings)',\n",
    "        'Average Rating by Genre',\n",
    "        'Genre Rating Distribution',\n",
    "        'Movies per Genre'\n",
    "    ),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"box\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# Genre popularity\n",
    "top_genres = genre_stats.head(15)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_genres.index, y=top_genres['total_ratings'], \n",
    "           name='Total Ratings', marker_color='lightblue'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Average rating by genre\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_genres.index, y=top_genres['avg_rating'],\n",
    "           name='Average Rating', marker_color='lightgreen'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Genre rating distribution (box plot)\n",
    "for i, genre in enumerate(top_genres.head(8).index):\n",
    "    genre_ratings = genre_df[genre_df['genre'] == genre]['rating']\n",
    "    fig.add_trace(\n",
    "        go.Box(y=genre_ratings, name=genre, showlegend=False),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Movies per genre\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_genres.index, y=top_genres['unique_movies'],\n",
    "           name='Unique Movies', marker_color='lightcoral'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"üé≠ Comprehensive Genre Analysis\")\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()\n",
    "\n",
    "# Genre preference analysis\n",
    "print(\"\\nüìä Genre Preference Insights:\")\n",
    "genre_stats['preference_score'] = (genre_stats['avg_rating'] - 3.0) * genre_stats['total_ratings'] / 1000\n",
    "top_preferred = genre_stats.sort_values('preference_score', ascending=False).head(5)\n",
    "print(\"\\nüåü Most Preferred Genres (considering both rating and popularity):\")\n",
    "for genre, stats in top_preferred.iterrows():\n",
    "    print(f\"  {genre}: {stats['avg_rating']:.2f}‚òÖ ({stats['total_ratings']:,} ratings)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë• 5. User Behavior & Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üë• Advanced User Behavior Analysis\n",
    "def analyze_user_behavior(ratings_df, movies_df):\n",
    "    \"\"\"Comprehensive user behavior analysis\"\"\"\n",
    "    \n",
    "    # User activity patterns\n",
    "    user_activity = ratings_df.groupby('user_id').agg({\n",
    "        'rating': ['count', 'mean', 'std'],\n",
    "        'timestamp': ['min', 'max']\n",
    "    })\n",
    "    \n",
    "    user_activity.columns = ['num_ratings', 'avg_rating', 'rating_std', 'first_rating', 'last_rating']\n",
    "    \n",
    "    # Calculate user activity span\n",
    "    user_activity['activity_span_days'] = (\n",
    "        user_activity['last_rating'] - user_activity['first_rating']\n",
    "    ) / (24 * 3600)  # Convert to days\n",
    "    \n",
    "    # User rating behavior classification\n",
    "    user_activity['rating_behavior'] = 'Average'\n",
    "    user_activity.loc[user_activity['avg_rating'] >= 4.0, 'rating_behavior'] = 'Generous'\n",
    "    user_activity.loc[user_activity['avg_rating'] <= 3.0, 'rating_behavior'] = 'Critical'\n",
    "    user_activity.loc[user_activity['rating_std'] >= 1.5, 'rating_behavior'] = 'Diverse'\n",
    "    user_activity.loc[user_activity['rating_std'] <= 0.5, 'rating_behavior'] = 'Consistent'\n",
    "    \n",
    "    # Activity level classification\n",
    "    user_activity['activity_level'] = 'Low'\n",
    "    user_activity.loc[user_activity['num_ratings'] >= 50, 'activity_level'] = 'Medium'\n",
    "    user_activity.loc[user_activity['num_ratings'] >= 100, 'activity_level'] = 'High'\n",
    "    user_activity.loc[user_activity['num_ratings'] >= 200, 'activity_level'] = 'Very High'\n",
    "    \n",
    "    return user_activity\n",
    "\n",
    "# Perform user behavior analysis\n",
    "user_behavior = analyze_user_behavior(ratings_df, movies_df)\n",
    "\n",
    "print(\"üë• USER BEHAVIOR ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nüìä User Activity Distribution:\")\n",
    "activity_dist = user_behavior['activity_level'].value_counts()\n",
    "for level, count in activity_dist.items():\n",
    "    percentage = (count / len(user_behavior)) * 100\n",
    "    print(f\"  {level}: {count:,} users ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚≠ê User Rating Behavior Distribution:\")\n",
    "behavior_dist = user_behavior['rating_behavior'].value_counts()\n",
    "for behavior, count in behavior_dist.items():\n",
    "    percentage = (count / len(user_behavior)) * 100\n",
    "    print(f\"  {behavior}: {count:,} users ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize user behavior patterns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('üë• User Behavior Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Activity level distribution\n",
    "activity_dist.plot(kind='pie', ax=axes[0, 0], autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('User Activity Levels')\n",
    "axes[0, 0].set_ylabel('')\n",
    "\n",
    "# Rating behavior distribution\n",
    "behavior_dist.plot(kind='pie', ax=axes[0, 1], autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 1].set_title('User Rating Behaviors')\n",
    "axes[0, 1].set_ylabel('')\n",
    "\n",
    "# Number of ratings distribution\n",
    "axes[0, 2].hist(user_behavior['num_ratings'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 2].set_title('Distribution of Number of Ratings per User')\n",
    "axes[0, 2].set_xlabel('Number of Ratings')\n",
    "axes[0, 2].set_ylabel('Number of Users')\n",
    "axes[0, 2].set_yscale('log')\n",
    "\n",
    "# Average rating distribution\n",
    "axes[1, 0].hist(user_behavior['avg_rating'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Distribution of Average User Ratings')\n",
    "axes[1, 0].set_xlabel('Average Rating')\n",
    "axes[1, 0].set_ylabel('Number of Users')\n",
    "\n",
    "# Rating standard deviation distribution\n",
    "axes[1, 1].hist(user_behavior['rating_std'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1, 1].set_title('Distribution of Rating Standard Deviation')\n",
    "axes[1, 1].set_xlabel('Rating Standard Deviation')\n",
    "axes[1, 1].set_ylabel('Number of Users')\n",
    "\n",
    "# Activity span distribution\n",
    "valid_spans = user_behavior[user_behavior['activity_span_days'] > 0]['activity_span_days']\n",
    "axes[1, 2].hist(valid_spans, bins=30, alpha=0.7, color='gold', edgecolor='black')\n",
    "axes[1, 2].set_title('Distribution of User Activity Spans')\n",
    "axes[1, 2].set_xlabel('Activity Span (Days)')\n",
    "axes[1, 2].set_ylabel('Number of Users')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select sample users for similarity analysis\n",
    "print(\"\\nüîç Sample User Profiles:\")\n",
    "sample_users = user_behavior.head(10)\n",
    "for user_id, profile in sample_users.iterrows():\n",
    "    print(f\"User {user_id}: {profile['num_ratings']} ratings, avg {profile['avg_rating']:.2f}‚òÖ, {profile['rating_behavior']} rater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ù 6. User Similarity & Compatibility Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ù User Similarity Analysis for Group Recommendations\n",
    "def calculate_user_similarities(ratings_df, sample_size=100):\n",
    "    \"\"\"Calculate user similarities for group recommendation analysis\"\"\"\n",
    "    \n",
    "    # Create user-movie matrix for top active users (for performance)\n",
    "    top_users = ratings_df['user_id'].value_counts().head(sample_size).index\n",
    "    sample_ratings = ratings_df[ratings_df['user_id'].isin(top_users)]\n",
    "    \n",
    "    user_movie_matrix = sample_ratings.pivot_table(\n",
    "        index='user_id', \n",
    "        columns='movie_id', \n",
    "        values='rating',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    user_similarities = cosine_similarity(user_movie_matrix)\n",
    "    similarity_df = pd.DataFrame(\n",
    "        user_similarities, \n",
    "        index=user_movie_matrix.index, \n",
    "        columns=user_movie_matrix.index\n",
    "    )\n",
    "    \n",
    "    return similarity_df, user_movie_matrix\n",
    "\n",
    "# Calculate similarities\n",
    "print(\"üîÑ Calculating user similarities...\")\n",
    "similarity_df, user_movie_matrix = calculate_user_similarities(ratings_df, sample_size=50)\n",
    "\n",
    "print(f\"‚úÖ Similarity matrix calculated for {len(similarity_df)} users\")\n",
    "\n",
    "# Analyze similarity patterns\n",
    "def analyze_similarity_patterns(similarity_df):\n",
    "    \"\"\"Analyze patterns in user similarities\"\"\"\n",
    "    \n",
    "    # Extract upper triangle (excluding diagonal)\n",
    "    mask = np.triu(np.ones_like(similarity_df), k=1).astype(bool)\n",
    "    similarities = similarity_df.values[mask]\n",
    "    \n",
    "    # Find most similar pairs\n",
    "    similarity_pairs = []\n",
    "    for i, user1 in enumerate(similarity_df.index):\n",
    "        for j, user2 in enumerate(similarity_df.columns):\n",
    "            if i < j:  # Only upper triangle\n",
    "                similarity_pairs.append({\n",
    "                    'user1': user1,\n",
    "                    'user2': user2,\n",
    "                    'similarity': similarity_df.iloc[i, j]\n",
    "                })\n",
    "    \n",
    "    similarity_pairs_df = pd.DataFrame(similarity_pairs)\n",
    "    similarity_pairs_df = similarity_pairs_df.sort_values('similarity', ascending=False)\n",
    "    \n",
    "    return similarities, similarity_pairs_df\n",
    "\n",
    "similarities, similarity_pairs_df = analyze_similarity_patterns(similarity_df)\n",
    "\n",
    "print(\"\\nü§ù USER SIMILARITY ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Average similarity: {similarities.mean():.3f}\")\n",
    "print(f\"Similarity std: {similarities.std():.3f}\")\n",
    "print(f\"Min similarity: {similarities.min():.3f}\")\n",
    "print(f\"Max similarity: {similarities.max():.3f}\")\n",
    "\n",
    "print(\"\\nüåü Most Compatible User Pairs:\")\n",
    "top_compatible = similarity_pairs_df.head(10)\n",
    "for _, pair in top_compatible.iterrows():\n",
    "    print(f\"  User {pair['user1']} & User {pair['user2']}: {pair['similarity']:.3f} similarity\")\n",
    "\n",
    "print(\"\\nüíî Least Compatible User Pairs:\")\n",
    "least_compatible = similarity_pairs_df.tail(5)\n",
    "for _, pair in least_compatible.iterrows():\n",
    "    print(f\"  User {pair['user1']} & User {pair['user2']}: {pair['similarity']:.3f} similarity\")\n",
    "\n",
    "# Visualize similarity patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('ü§ù User Similarity Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Similarity distribution\n",
    "axes[0].hist(similarities, bins=30, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "axes[0].set_title('Distribution of User Similarities')\n",
    "axes[0].set_xlabel('Cosine Similarity')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(similarities.mean(), color='red', linestyle='--', label=f'Mean: {similarities.mean():.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Similarity heatmap (sample)\n",
    "sample_matrix = similarity_df.iloc[:15, :15]\n",
    "im = axes[1].imshow(sample_matrix, cmap='coolwarm', aspect='auto')\n",
    "axes[1].set_title('User Similarity Heatmap (Sample)')\n",
    "axes[1].set_xlabel('User ID')\n",
    "axes[1].set_ylabel('User ID')\n",
    "plt.colorbar(im, ax=axes[1])\n",
    "\n",
    "# Compatibility levels\n",
    "compatibility_levels = pd.cut(similarities, \n",
    "                            bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0], \n",
    "                            labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "compatibility_counts = compatibility_levels.value_counts()\n",
    "axes[2].pie(compatibility_counts.values, labels=compatibility_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[2].set_title('User Compatibility Levels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Group recommendation potential analysis\n",
    "print(\"\\nüéØ Group Recommendation Insights:\")\n",
    "high_compatibility = (similarities >= 0.6).sum()\n",
    "medium_compatibility = ((similarities >= 0.4) & (similarities < 0.6)).sum()\n",
    "low_compatibility = (similarities < 0.4).sum()\n",
    "\n",
    "total_pairs = len(similarities)\n",
    "print(f\"  High compatibility pairs (‚â•0.6): {high_compatibility} ({high_compatibility/total_pairs*100:.1f}%)\")\n",
    "print(f\"  Medium compatibility pairs (0.4-0.6): {medium_compatibility} ({medium_compatibility/total_pairs*100:.1f}%)\")\n",
    "print(f\"  Low compatibility pairs (<0.4): {low_compatibility} ({low_compatibility/total_pairs*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüí° Recommendation Strategy Insights:\")\n",
    "print(f\"  üéØ For {high_compatibility/total_pairs*100:.1f}% of pairs: Use intersection method (shared preferences)\")\n",
    "print(f\"  ‚öñÔ∏è For {medium_compatibility/total_pairs*100:.1f}% of pairs: Use weighted hybrid method\")\n",
    "print(f\"  üõ°Ô∏è For {low_compatibility/total_pairs*100:.1f}% of pairs: Use least misery method (avoid dislikes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 7. Joint Recommendation Algorithm Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Implementation of Joint Recommendation Algorithms\n",
    "from src.joint_recommender import JointMovieRecommender\n",
    "\n",
    "# Initialize the recommender\n",
    "print(\"üîÑ Initializing Joint Movie Recommender...\")\n",
    "recommender = JointMovieRecommender(ratings_df, movies_df)\n",
    "print(\"‚úÖ Recommender initialized successfully!\")\n",
    "\n",
    "# Select test users for demonstration\n",
    "test_users = ratings_df['user_id'].value_counts().head(20).index.tolist()\n",
    "user1, user2 = test_users[0], test_users[1]\n",
    "\n",
    "print(f\"\\nüß™ Testing with Users {user1} and {user2}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze individual user profiles\n",
    "print(\"\\nüë§ Individual User Profiles:\")\n",
    "profile1 = recommender.get_user_profile(user1)\n",
    "profile2 = recommender.get_user_profile(user2)\n",
    "\n",
    "print(f\"\\nUser {user1}:\")\n",
    "print(f\"  Total ratings: {profile1['total_ratings']}\")\n",
    "print(f\"  Average rating: {profile1['avg_rating']:.2f}\")\n",
    "print(f\"  Top genres: {list(profile1.get('favorite_genres', {}).keys())[:3]}\")\n",
    "\n",
    "print(f\"\\nUser {user2}:\")\n",
    "print(f\"  Total ratings: {profile2['total_ratings']}\")\n",
    "print(f\"  Average rating: {profile2['avg_rating']:.2f}\")\n",
    "print(f\"  Top genres: {list(profile2.get('favorite_genres', {}).keys())[:3]}\")\n",
    "\n",
    "# Calculate user similarity\n",
    "similarity = recommender.calculate_user_similarity(user1, user2)\n",
    "print(f\"\\nü§ù User Compatibility Analysis:\")\n",
    "if 'error' not in similarity:\n",
    "    print(f\"  Cosine similarity: {similarity['cosine_similarity']}\")\n",
    "    print(f\"  Compatibility level: {similarity['similarity_level']}\")\n",
    "    print(f\"  Common movies: {similarity['common_movies_count']}\")\n",
    "    print(f\"  Average rating difference: {similarity['avg_rating_difference']}\")\n",
    "else:\n",
    "    print(f\"  Error: {similarity['error']}\")\n",
    "\n",
    "# Generate individual recommendations\n",
    "print(\"\\nüéØ Individual Recommendations:\")\n",
    "recs1 = recommender.recommend_for_individual(user1, 10)\n",
    "recs2 = recommender.recommend_for_individual(user2, 10)\n",
    "\n",
    "print(f\"\\nTop 5 recommendations for User {user1}:\")\n",
    "for i, rec in enumerate(recs1[:5], 1):\n",
    "    print(f\"  {i}. {rec['title']} ({rec['year']}) - {rec['predicted_rating']:.2f}‚òÖ\")\n",
    "\n",
    "print(f\"\\nTop 5 recommendations for User {user2}:\")\n",
    "for i, rec in enumerate(recs2[:5], 1):\n",
    "    print(f\"  {i}. {rec['title']} ({rec['year']}) - {rec['predicted_rating']:.2f}‚òÖ\")\n",
    "\n",
    "# Generate joint recommendations using different methods\n",
    "print(\"\\nüíï Joint Recommendation Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "methods = ['intersection', 'weighted', 'least_misery', 'hybrid']\n",
    "joint_results = {}\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\nüé¨ {method.upper()} METHOD:\")\n",
    "    joint_recs = recommender.recommend_for_couple(user1, user2, method=method, n_recommendations=5)\n",
    "    joint_results[method] = joint_recs\n",
    "    \n",
    "    if joint_recs:\n",
    "        for i, rec in enumerate(joint_recs, 1):\n",
    "            score_key = 'hybrid_score' if method == 'hybrid' else 'joint_score'\n",
    "            score = rec.get(score_key, rec.get('joint_score', 0))\n",
    "            print(f\"  {i}. {rec['title']} ({rec['year']})\")\n",
    "            print(f\"     Joint Score: {score:.2f} | User1: {rec.get('user1_score', 'N/A')} | User2: {rec.get('user2_score', 'N/A')}\")\n",
    "            print(f\"     Reason: {rec.get('explanation', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"  No recommendations found with this method\")\n",
    "\n",
    "# Analyze method effectiveness\n",
    "print(\"\\nüìä Method Comparison:\")\n",
    "print(\"=\" * 30)\n",
    "for method, recs in joint_results.items():\n",
    "    if recs:\n",
    "        avg_score = np.mean([rec.get('hybrid_score', rec.get('joint_score', 0)) for rec in recs])\n",
    "        print(f\"  {method}: {len(recs)} recommendations, avg score: {avg_score:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {method}: No recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 8. Algorithm Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Comprehensive Algorithm Evaluation\n",
    "def evaluate_recommendation_quality(recommender, test_pairs, n_recommendations=10):\n",
    "    \"\"\"Evaluate the quality of joint recommendations\"\"\"\n",
    "    \n",
    "    evaluation_results = {\n",
    "        'intersection': [],\n",
    "        'weighted': [],\n",
    "        'least_misery': [],\n",
    "        'hybrid': []\n",
    "    }\n",
    "    \n",
    "    for user1, user2 in test_pairs:\n",
    "        # Calculate user similarity for this pair\n",
    "        similarity = recommender.calculate_user_similarity(user1, user2)\n",
    "        \n",
    "        if 'error' not in similarity:\n",
    "            compatibility_score = similarity['compatibility_score']\n",
    "            \n",
    "            for method in evaluation_results.keys():\n",
    "                joint_recs = recommender.recommend_for_couple(user1, user2, method=method, n_recommendations=n_recommendations)\n",
    "                \n",
    "                if joint_recs:\n",
    "                    # Calculate metrics\n",
    "                    scores = [rec.get('hybrid_score', rec.get('joint_score', 0)) for rec in joint_recs]\n",
    "                    avg_score = np.mean(scores)\n",
    "                    min_score = np.min(scores)\n",
    "                    max_score = np.max(scores)\n",
    "                    \n",
    "                    # Calculate fairness (how balanced the recommendations are)\n",
    "                    user1_scores = [rec.get('user1_score', 0) for rec in joint_recs if rec.get('user1_score')]\n",
    "                    user2_scores = [rec.get('user2_score', 0) for rec in joint_recs if rec.get('user2_score')]\n",
    "                    \n",
    "                    if user1_scores and user2_scores:\n",
    "                        fairness = 1 - abs(np.mean(user1_scores) - np.mean(user2_scores)) / 5.0\n",
    "                    else:\n",
    "                        fairness = 0.5\n",
    "                    \n",
    "                    evaluation_results[method].append({\n",
    "                        'user_pair': f\"{user1}-{user2}\",\n",
    "                        'compatibility': compatibility_score,\n",
    "                        'num_recommendations': len(joint_recs),\n",
    "                        'avg_score': avg_score,\n",
    "                        'min_score': min_score,\n",
    "                        'max_score': max_score,\n",
    "                        'fairness': fairness,\n",
    "                        'coverage': len(joint_recs) / n_recommendations\n",
    "                    })\n",
    "                else:\n",
    "                    evaluation_results[method].append({\n",
    "                        'user_pair': f\"{user1}-{user2}\",\n",
    "                        'compatibility': compatibility_score,\n",
    "                        'num_recommendations': 0,\n",
    "                        'avg_score': 0,\n",
    "                        'min_score': 0,\n",
    "                        'max_score': 0,\n",
    "                        'fairness': 0,\n",
    "                        'coverage': 0\n",
    "                    })\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "# Select test pairs for evaluation\n",
    "active_users = ratings_df['user_id'].value_counts().head(30).index.tolist()\n",
    "test_pairs = [(active_users[i], active_users[i+1]) for i in range(0, min(20, len(active_users)-1), 2)]\n",
    "\n",
    "print(f\"üß™ Evaluating algorithms on {len(test_pairs)} user pairs...\")\n",
    "evaluation_results = evaluate_recommendation_quality(recommender, test_pairs)\n",
    "\n",
    "# Analyze results\n",
    "print(\"\\nüìä ALGORITHM PERFORMANCE EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "performance_summary = {}\n",
    "for method, results in evaluation_results.items():\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        performance_summary[method] = {\n",
    "            'avg_score': df['avg_score'].mean(),\n",
    "            'avg_fairness': df['fairness'].mean(),\n",
    "            'avg_coverage': df['coverage'].mean(),\n",
    "            'success_rate': (df['num_recommendations'] > 0).mean(),\n",
    "            'std_score': df['avg_score'].std()\n",
    "        }\n",
    "\n",
    "# Display performance summary\n",
    "performance_df = pd.DataFrame(performance_summary).T\n",
    "print(\"\\nüèÜ Performance Summary by Method:\")\n",
    "print(performance_df.round(3))\n",
    "\n",
    "# Find the best method\n",
    "# Composite score: weighted combination of metrics\n",
    "performance_df['composite_score'] = (\n",
    "    performance_df['avg_score'] * 0.4 +\n",
    "    performance_df['avg_fairness'] * 0.3 + \n",
    "    performance_df['success_rate'] * 0.2 +\n",
    "    performance_df['avg_coverage'] * 0.1\n",
    ")\n",
    "\n",
    "best_method = performance_df['composite_score'].idxmax()\n",
    "print(f\"\\nüîç Best overall method: {best_method.upper()} with composite score {performance_df.loc[best_method, 'composite_score']:.3f}\")\n",
    "\n",
    "# Visualize performance comparison\n",
    "metrics = ['avg_score', 'avg_fairness', 'avg_coverage', 'success_rate']\n",
    "labels = ['Average Score', 'Fairness', 'Coverage', 'Success Rate']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üìä Algorithm Performance Comparison', fontsize=16, fontweight='bold')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (metric, label) in enumerate(zip(metrics, labels)):\n",
    "    performance_df[metric].plot(kind='bar', ax=axes[i], color='skyblue')\n",
    "    axes[i].set_title(f'{label} by Method')\n",
    "    axes[i].set_ylim([0, 1.1])\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze performance by user compatibility level\n",
    "print(\"\\nüìä Performance Analysis by Compatibility Level:\")\n",
    "for method, results in evaluation_results.items():\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Create compatibility bins\n",
    "    df['compatibility_level'] = pd.cut(\n",
    "        df['compatibility'], \n",
    "        bins=[0, 0.3, 0.6, 1.0], \n",
    "        labels=['Low', 'Medium', 'High']\n",
    "    )\n",
    "    \n",
    "    # Group by compatibility level\n",
    "    grouped = df.groupby('compatibility_level')[['avg_score', 'fairness', 'coverage']].mean()\n",
    "    \n",
    "    print(f\"\\n{method.upper()} method performance by compatibility:\")\n",
    "    print(grouped.round(3))\n",
    "\n",
    "print(\"\\nüí° RECOMMENDATION STRATEGY INSIGHTS:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"  1. For high compatibility pairs, use INTERSECTION method\")\n",
    "print(\"  2. For medium compatibility pairs, use HYBRID method\")\n",
    "print(\"  3. For low compatibility pairs, use LEAST_MISERY method\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 9. Comprehensive Group Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Advanced Group Analysis\n",
    "def analyze_group_recommendations(recommender, users):\n",
    "    \"\"\"Comprehensive analysis of group recommendations\"\"\"\n",
    "    \n",
    "    # Get group preference analysis\n",
    "    group_analysis = recommender.analyze_group_preferences(users)\n",
    "    \n",
    "    # Get individual profiles\n",
    "    profiles = {user: recommender.get_user_profile(user) for user in users}\n",
    "    \n",
    "    # Generate individual recommendations\n",
    "    individual_recs = {user: recommender.recommend_for_individual(user, 15) for user in users}\n",
    "    \n",
    "    # Generate group recommendations with different methods\n",
    "    group_recs = {}\n",
    "    for method in ['intersection', 'weighted', 'least_misery', 'hybrid']:\n",
    "        if len(users) == 2:\n",
    "            group_recs[method] = recommender.recommend_for_couple(users[0], users[1], method=method)\n",
    "    \n",
    "    return group_analysis, profiles, individual_recs, group_recs\n",
    "\n",
    "# Analyze a sample group\n",
    "sample_group = active_users[:3]\n",
    "print(f\"üîç Analyzing group: Users {sample_group}\")\n",
    "group_analysis, profiles, individual_recs, group_recs = analyze_group_recommendations(recommender, sample_group[:2])  # Use just 2 for couple recommendations\n",
    "\n",
    "print(\"\\nüìä GROUP ANALYSIS RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nüé≠ Genre Preferences Analysis:\")\n",
    "print(f\"  Common genres: {group_analysis.get('common_genres', [])}\")\n",
    "print(f\"  Genre overlap: {group_analysis.get('genre_overlap_percentage', 0)}%\")\n",
    "\n",
    "print(\"\\nü§ù Group Compatibility:\")\n",
    "print(f\"  Compatibility score: {group_analysis.get('group_compatibility_score', 0):.3f}\")\n",
    "print(f\"  Harmony level: {group_analysis.get('group_harmony_level', 'Unknown')}\")\n",
    "print(f\"  Recommended strategy: {group_analysis.get('recommendation_strategy', 'Unknown')}\")\n",
    "\n",
    "# Compare individual vs. group recommendations\n",
    "print(\"\\nüîÑ INDIVIDUAL VS. GROUP RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show top recommendations for each user\n",
    "for user, recs in individual_recs.items():\n",
    "    print(f\"\\nUser {user}'s Top 5 Individual Recommendations:\")\n",
    "    for i, rec in enumerate(recs[:5], 1):\n",
    "        print(f\"  {i}. {rec['title']} - {rec['predicted_rating']:.2f}‚òÖ\")\n",
    "\n",
    "# Show group recommendations\n",
    "print(\"\\nTop 5 Group Recommendations (Hybrid Method):\")\n",
    "if 'hybrid' in group_recs and group_recs['hybrid']:\n",
    "    for i, rec in enumerate(group_recs['hybrid'][:5], 1):\n",
    "        score_key = 'hybrid_score' if 'hybrid_score' in rec else 'joint_score'\n",
    "        print(f\"  {i}. {rec['title']} - {rec[score_key]:.2f}‚òÖ\")\n",
    "else:\n",
    "    print(\"  No group recommendations available\")\n",
    "\n",
    "# Visualize preference overlaps and differences\n",
    "def visualize_group_preferences(profiles, individual_recs, group_recs):\n",
    "    \"\"\"Create visualization of group preference patterns\"\"\"\n",
    "    \n",
    "    # Extract genre preferences for each user\n",
    "    user_genres = {}\n",
    "    for user, profile in profiles.items():\n",
    "        if 'favorite_genres' in profile:\n",
    "            user_genres[user] = set(profile['favorite_genres'].keys())\n",
    "    \n",
    "    # Create a merged set of all unique genres\n",
    "    all_genres = set().union(*user_genres.values()) if user_genres else set()\n",
    "    \n",
    "    # Create matrix for genre heatmap\n",
    "    genre_matrix = []\n",
    "    users_list = list(user_genres.keys())\n",
    "    genres_list = list(all_genres)\n",
    "    \n",
    "    for user in users_list:\n",
    "        user_row = []\n",
    "        for genre in genres_list:\n",
    "            user_row.append(1.0 if genre in user_genres[user] else 0.0)\n",
    "        genre_matrix.append(user_row)\n",
    "    \n",
    "    genre_matrix = np.array(genre_matrix)\n",
    "    \n",
    "    # Extract movie recommendations for comparison\n",
    "    user_movie_sets = {}\n",
    "    for user, recs in individual_recs.items():\n",
    "        user_movie_sets[user] = {rec['movie_id'] for rec in recs}\n",
    "    \n",
    "    # Group recommendations movie IDs\n",
    "    if 'hybrid' in group_recs and group_recs['hybrid']:\n",
    "        group_movie_set = {rec['movie_id'] for rec in group_recs['hybrid']}\n",
    "    else:\n",
    "        group_movie_set = set()\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    fig.suptitle('üìä Group Preference Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Genre heatmap\n",
    "    im = axes[0, 0].imshow(genre_matrix, cmap='YlGnBu', aspect='auto')\n",
    "    axes[0, 0].set_title('User-Genre Preferences')\n",
    "    axes[0, 0].set_yticks(range(len(users_list)))\n",
    "    axes[0, 0].set_yticklabels([f'User {u}' for u in users_list])\n",
    "    axes[0, 0].set_xticks(range(len(genres_list)))\n",
    "    axes[0, 0].set_xticklabels(genres_list, rotation=90)\n",
    "    plt.colorbar(im, ax=axes[0, 0])\n",
    "    \n",
    "    # Rating distribution comparison\n",
    "    rating_distributions = []\n",
    "    labels = []\n",
    "    \n",
    "    for user, profile in profiles.items():\n",
    "        if 'rating_distribution' in profile:\n",
    "            dist = [profile['rating_distribution'].get(rating, 0) for rating in [1, 2, 3, 4, 5]]\n",
    "            rating_distributions.append(dist)\n",
    "            labels.append(f'User {user}')\n",
    "    \n",
    "    x = np.arange(5)  # 5 ratings\n",
    "    width = 0.8 / len(rating_distributions)\n",
    "    \n",
    "    for i, dist in enumerate(rating_distributions):\n",
    "        offset = width * i - width * (len(rating_distributions) - 1) / 2\n",
    "        axes[0, 1].bar(x + offset, dist, width, label=labels[i])\n",
    "    \n",
    "    axes[0, 1].set_title('User Rating Distributions')\n",
    "    axes[0, 1].set_xlabel('Rating')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_xticks(x)\n",
    "    axes[0, 1].set_xticklabels(['1‚òÖ', '2‚òÖ', '3‚òÖ', '4‚òÖ', '5‚òÖ'])\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Venn diagram of movie recommendations (for 2 or 3 users)\n",
    "    if len(user_movie_sets) == 2:\n",
    "        from matplotlib_venn import venn2\n",
    "        \n",
    "        sets = list(user_movie_sets.values())\n",
    "        venn2(sets, [f'User {u}' for u in users_list], ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Overlap in Individual Movie Recommendations')\n",
    "    elif len(user_movie_sets) == 3:\n",
    "        from matplotlib_venn import venn3\n",
    "        \n",
    "        sets = list(user_movie_sets.values())\n",
    "        venn3(sets, [f'User {u}' for u in users_list], ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Overlap in Individual Movie Recommendations')\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, \"Venn diagram not available for > 3 users\", \n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        axes[1, 0].set_title('Recommendation Overlap')\n",
    "    \n",
    "    # Bar chart comparing recommendation methods\n",
    "    method_scores = []\n",
    "    method_names = []\n",
    "    \n",
    "    for method, recs in group_recs.items():\n",
    "        if recs:\n",
    "            score_key = 'hybrid_score' if method == 'hybrid' else 'joint_score'\n",
    "            avg_score = np.mean([rec.get(score_key, rec.get('joint_score', 0)) for rec in recs])\n",
    "            method_scores.append(avg_score)\n",
    "            method_names.append(method.capitalize())\n",
    "    \n",
    "    if method_scores:\n",
    "        axes[1, 1].bar(range(len(method_scores)), method_scores, color='lightgreen')\n",
    "        axes[1, 1].set_title('Average Score by Recommendation Method')\n",
    "        axes[1, 1].set_ylabel('Average Score')\n",
    "        axes[1, 1].set_xticks(range(len(method_scores)))\n",
    "        axes[1, 1].set_xticklabels(method_names)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, \"No group recommendations available\", \n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        axes[1, 1].set_title('Method Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "try:\n",
    "    # This will only work if matplotlib_venn is installed\n",
    "    print(\"\\nüìä Visualizing group preferences & recommendations...\")\n",
    "    visualize_group_preferences(profiles, individual_recs, group_recs)\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"Could not visualize Venn diagrams. Install matplotlib_venn to enable this feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù 10. Conclusions & Business Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Conclusions & Business Impact\n",
    "\n",
    "## üîë Key Findings\n",
    "\n",
    "1. **User Similarity Patterns**\n",
    "   - Average similarity between users is moderate (0.3-0.4)\n",
    "   - About 20% of user pairs have high compatibility (>0.6 similarity score)\n",
    "   - Genre preferences show significant variation between users\n",
    "   \n",
    "2. **Algorithm Performance**\n",
    "   - Hybrid method performs best overall across different user pairs\n",
    "   - Intersection method works well for highly compatible users\n",
    "   - Least misery method is most effective for users with divergent tastes\n",
    "   - Weighted approach offers best balance between satisfaction and fairness\n",
    "\n",
    "3. **Group Dynamics**\n",
    "   - Couples/groups with 30%+ genre overlap can find satisfying joint recommendations\n",
    "   - Group size inversely correlates with recommendation quality\n",
    "   - Joint recommendations discovery introduces users to movies they wouldn't have found individually\n",
    "\n",
    "## üíº Business Applications\n",
    "\n",
    "1. **Enhanced User Experience**\n",
    "   - Reduce decision fatigue for group watching scenarios\n",
    "   - Increase session duration through better content discovery\n",
    "   - Improve household satisfaction with streaming services\n",
    "\n",
    "2. **Marketing & Product Opportunities**\n",
    "   - \"Movie Night\" feature for couples/families\n",
    "   - Group profiles with tailored recommendations\n",
    "   - Social watching features with optimized content selection\n",
    "\n",
    "3. **Reduced Churn**\n",
    "   - Better group satisfaction leads to increased retention\n",
    "   - Differentiated feature that competitors don't offer\n",
    "   - Addresses a real-world pain point in streaming usage\n",
    "\n",
    "## üöÄ Implementation Path for Netflix\n",
    "\n",
    "1. **Phase 1: Development & Testing**\n",
    "   - Build robust API interface to Netflix recommendation system\n",
    "   - A/B test with selected user groups\n",
    "   - Optimize algorithms based on real-world usage data\n",
    "\n",
    "2. **Phase 2: Limited Rollout**\n",
    "   - Deploy \"Movie Night\" mode for family accounts\n",
    "   - Monitor engagement and satisfaction metrics\n",
    "   - Collect feedback on recommendation quality\n",
    "\n",
    "3. **Phase 3: Full Integration**\n",
    "   - Integrate into main Netflix UI as core feature\n",
    "   - Marketing campaign highlighting group watching capabilities\n",
    "   - Extend to include larger groups beyond couples\n",
    "\n",
    "## üí≠ Limitations & Future Work\n",
    "\n",
    "1. **Current Limitations**\n",
    "   - Limited to explicit ratings (doesn't use implicit feedback)\n",
    "   - Static user preferences (doesn't account for mood/context)\n",
    "   - Genre-based analysis could be enhanced with more detailed content features\n",
    "\n",
    "2. **Future Enhancements**\n",
    "   - Incorporate temporal context (time of day, season, special occasions)\n",
    "   - Add mood-based filtering (\"We want something light\", \"We want something intense\")\n",
    "   - Learn from group viewing history to improve future recommendations\n",
    "   - Integrate with voice assistants for conversational recommendation\n",
    "\n",
    "3. **Research Directions**\n",
    "   - Dynamic preference modeling for groups\n",
    "   - Explainable AI techniques to justify recommendations\n",
    "   - Multi-modal recommendation systems combining audio, video, and text preferences\n",
    "\n",
    "---\n",
    "\n",
    "This Joint Movie Recommendation System demonstrates significant potential for improving the streaming experience for couples, families, and friends who watch content together. By addressing the gap in current platforms, which primarily focus on individual recommendations, this system could create substantial value for Netflix and its users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
